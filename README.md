# Binary-Integer-Multiplier
Trained a recurrent neural network (RNN) to perform multiplication of two integers written in their binary representations.

# README.md

## Multiplication RNN

This directory contains Python scripts for training a Recurrent Neural Network (RNN) to perform multiplication of binary integers (A * B = C). The RNN is implemented using the TensorFlow library. The main script (`main.py`) loads hyperparameters from a JSON file, generates training and test datasets, and trains the RNN model. Additionally, there is an alternative implementation using PyTorch in the file `main_torch.py`, but it is still under debugging.

### Files in the Directory:

1. **main.py**: This script is the main entry point for training the RNN using TensorFlow. It includes the following functions:

    - **load_hyperparameters(param_file)**: This function loads hyperparameters from a JSON file.

    - **generate_dataset(seed, train_size, test_size)**: This function generates training and test datasets for the multiplication task. It uses a specified random seed for reproducibility.

    - **train_rnn(train_dataset, test_dataset, hyperparameters)**: This function trains the RNN model using the provided datasets and hyperparameters. It builds an LSTM model, compiles it, trains it, and plots the training and test losses.

    - **main()**: The main function of the script. It parses command line arguments, loads hyperparameters, generates datasets, splits the test dataset, and calls the `train_rnn` function.

2. **param.json**: This JSON file contains hyperparameters for the RNN model, including input and output sizes, hidden layer size, learning rate, number of epochs, and batch size.

   - **`input_size`**: The size of the input vector for each sequence. In this context, it represents the length of the binary representation of the two integers A and B concatenated with a zero. The provided value `17` suggests that each input sequence is 17 elements long.

   - **`output_size`**: The size of the output vector for each sequence. It represents the length of the binary representation of the product C. The value `17` suggests that each output sequence is 17 elements long.

   - **`hidden_size`**: The number of units (neurons) in the hidden layer of the LSTM (Long Short-Term Memory) neural network. This parameter controls the capacity and complexity of the model. The provided value `32` suggests there are 32 hidden units in the LSTM layer.

   - **`learning_rate`**: The learning rate determines the step size at each iteration during the optimization process. It influences how quickly or slowly the model learns. The provided value `0.001` is a common starting point for learning rates.

   - **`epochs`**: The number of times the entire training dataset is processed by the model. One epoch consists of one forward pass and one backward pass of all the training sequences. The provided value `10` suggests training for ten epochs.

   - **`batch_size`**: The number of training sequences utilized in one iteration. It defines the number of samples that will be propagated through the network before updating the model's parameters. The provided value `64` indicates that the model is updated after processing each batch of 64 sequences.

These hyperparameters control the architecture and training dynamics of the neural network. It's common to experiment with different values for these parameters to achieve optimal performance on the specific task at hand.

3. **main_torch.py**: An alternative implementation of the RNN using PyTorch. It is still under debugging and not fully functional.

4. **loss_plot.png**: A plot of the training and test losses over epochs generated by the TensorFlow implementation.

### How to Run:

To train the RNN using the TensorFlow implementation, use the following command:

```bash
python main.py --param param.json --train-size 10000 --test-size 100 --seed 1234
```

This command specifies the hyperparameter file (`param.json`), the size of the training and test sets, and the random seed for dataset generation.

### Results:

Upon running the script, you will see the model summary, training and test loss for each epoch, and a plot showing the training and test losses over epochs. The loss plot is saved as `loss_plot.png`.

### Note:

- The TensorFlow model is optimized for CPU instructions, and a message may appear indicating that the binary is optimized for certain CPU instructions. If needed, you can rebuild TensorFlow with appropriate compiler flags.

- The PyTorch implementation (`main_torch.py`) is currently under debugging and may not produce accurate results.

Feel free to explore and experiment with different hyperparameters or contribute improvements to the PyTorch implementation. If you encounter any issues or have suggestions, please feel free to open an issue or contribute to the project.

**Happy experimenting with neural networks!**
